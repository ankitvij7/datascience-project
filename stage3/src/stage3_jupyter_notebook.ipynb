{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3 - Enitity Matching Notebook\n",
    "- Ankit Vij\n",
    "- Amanpreet Singh Saini\n",
    "- Joel Haynie\n",
    "\n",
    "Date: 2018-04-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stages of our Pipeline: Clean -> Block -> Label -> ML'ing a Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean\n",
    "We executed ```prepTableA.py``` & ```prepTableB.py```.\n",
    "\n",
    "These take the raw two tables from Stage # 2 to a cleaned Table A & B\n",
    "\n",
    "These go Column by Column and clean up and transform the data into a consistant and usable form.  Defaults were also defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Blocking\n",
    " We executed the ```blocker.py``` below is a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# Load csv files as dataframes and set the key attribute in the dataframe\n",
    "path_A = '..'+ os.sep + 'data' + os.sep + 'A.csv'\n",
    "A = em.read_csv_metadata(path_A, key='ID')\n",
    "path_B = '..'+ os.sep + 'data' + os.sep + 'B.csv'\n",
    "B = em.read_csv_metadata(path_B, key='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Tuples: 3250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Directed By</th>\n",
       "      <th>Written By</th>\n",
       "      <th>Box Office</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_0001</td>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>0</td>\n",
       "      <td>NOT RATED</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>Anthony Russo</td>\n",
       "      <td>Christopher Markus</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>156</td>\n",
       "      <td>Marvel Studios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_0002</td>\n",
       "      <td>Tomb Raider</td>\n",
       "      <td>69</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Action</td>\n",
       "      <td>Roar Uthaug</td>\n",
       "      <td>Geneva Robertson-Dworet</td>\n",
       "      <td>31318108</td>\n",
       "      <td>2018-03-16</td>\n",
       "      <td>118</td>\n",
       "      <td>GK Films</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_0003</td>\n",
       "      <td>Black Panther</td>\n",
       "      <td>78</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>Ryan Coogler</td>\n",
       "      <td>Ryan Coogler</td>\n",
       "      <td>614258236</td>\n",
       "      <td>2018-02-16</td>\n",
       "      <td>134</td>\n",
       "      <td>Marvel Studios</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                   Title  Score     Rating    Genre    Directed By  \\\n",
       "0  A_0001  Avengers: Infinity War      0  NOT RATED  Fantasy  Anthony Russo   \n",
       "1  A_0002             Tomb Raider     69      PG-13   Action    Roar Uthaug   \n",
       "2  A_0003           Black Panther     78      PG-13   Sci-Fi   Ryan Coogler   \n",
       "\n",
       "                Written By  Box Office Release Date  Runtime          Studio  \n",
       "0       Christopher Markus           0   2018-04-27      156  Marvel Studios  \n",
       "1  Geneva Robertson-Dworet    31318108   2018-03-16      118        GK Films  \n",
       "2             Ryan Coogler   614258236   2018-02-16      134  Marvel Studios  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Tuples in A\n",
    "print(\"A Tuples: \" + str(len(A)))\n",
    "A.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Tuples: 3005\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Directed By</th>\n",
       "      <th>Written By</th>\n",
       "      <th>Box Office</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B_0001</td>\n",
       "      <td>Justice League</td>\n",
       "      <td>40</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Zack Snyder</td>\n",
       "      <td>Chris Terrio</td>\n",
       "      <td>227032490</td>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>110</td>\n",
       "      <td>Warner Bros. Pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_0002</td>\n",
       "      <td>Ferdinand</td>\n",
       "      <td>71</td>\n",
       "      <td>PG</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Carlos Saldanha</td>\n",
       "      <td>Robert L. Baird</td>\n",
       "      <td>70466891</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_0003</td>\n",
       "      <td>Court</td>\n",
       "      <td>100</td>\n",
       "      <td>NOT RATED</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Chaitanya Tamhane</td>\n",
       "      <td>Chaitanya Tamhane</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>116</td>\n",
       "      <td>Zeitgeist Films</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID           Title  Score     Rating  Genre        Directed By  \\\n",
       "0  B_0001  Justice League     40      PG-13  Drama        Zack Snyder   \n",
       "1  B_0002       Ferdinand     71         PG  Drama    Carlos Saldanha   \n",
       "2  B_0003           Court    100  NOT RATED  Drama  Chaitanya Tamhane   \n",
       "\n",
       "          Written By  Box Office Release Date  Runtime                 Studio  \n",
       "0       Chris Terrio   227032490   2017-11-17      110  Warner Bros. Pictures  \n",
       "1    Robert L. Baird    70466891   2017-12-15        0                    NaN  \n",
       "2  Chaitanya Tamhane           0   2015-07-15      116        Zeitgeist Films  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Tuples in A\n",
    "print(\"A Tuples: \" + str(len(B)))\n",
    "B.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Tuple Matches: 9766250\n"
     ]
    }
   ],
   "source": [
    "print(\"Possible Tuple Matches: \" + str(len(A)*len(B)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gernerate 3 candidate sets:\n",
    "1. AttrEquivalenceBlocker on the movie 'Release Date'\n",
    "1. OverlapBlocker on the movie 'Title'\n",
    "1. AttrEquivalenceBlocker on the movie 'Title'.\n",
    "\n",
    "These are all Unioned together into set D\n",
    "Finally a Rule Based Blocker over the Levenshtein distance for the 'Title' < 0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 Set Size:  191237\n"
     ]
    }
   ],
   "source": [
    "#1 \n",
    "ab = em.AttrEquivalenceBlocker()\n",
    "# Block tables using 'year' attribute : same year include in candidate set\n",
    "C1 = ab.block_tables(A, B, 'Release Date', 'Release Date',\n",
    "                     l_output_attrs=['Title', 'Genre', 'Score', 'Release Date', 'Rating', 'Directed By', 'Written By', 'Studio'],\n",
    "                     r_output_attrs=['Title', 'Genre', 'Score', 'Release Date', 'Rating', 'Directed By', 'Written By', 'Studio'])\n",
    "print(\"C1 Set Size: \", len(C1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2 Set Size:  1826\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "ob = em.OverlapBlocker()\n",
    "# Block over title attribute\n",
    "C2 = ob.block_tables(A, B, 'Title', 'Title', show_progress=False, overlap_size=2, rem_stop_words=True,\n",
    "                     l_output_attrs=['Title', 'Genre', 'Score', 'Release Date', 'Rating', 'Directed By', 'Written By','Studio'],\n",
    "                     r_output_attrs=['Title', 'Genre', 'Score', 'Release Date', 'Rating', 'Directed By', 'Written By','Studio'])\n",
    "print(\"C2 Set Size: \", len(C2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3 Set Size:  607\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "# Attribute Equivalence Blocker for Title\n",
    "C3 = ab.block_tables(A, B, 'Title', 'Title',\n",
    "                     l_output_attrs=['Title', 'Genre', 'Score', 'Release Date', 'Rating', 'Directed By', 'Written By','Studio'],\n",
    "                     r_output_attrs=['Title', 'Genre', 'Score', 'Release Date', 'Rating', 'Directed By', 'Written By','Studio'])\n",
    "print(\"C3 Set Size: \", len(C3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D Set Size:  192807\n"
     ]
    }
   ],
   "source": [
    "#Union the last three\n",
    "D = em.combine_blocker_outputs_via_union([C1, C2, C3])\n",
    "print(\"D Set Size: \", len(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C Set Size:  3335\n"
     ]
    }
   ],
   "source": [
    "# Rule based blocker on D\n",
    "block_f = em.get_features_for_blocking(A, B, validate_inferred_attr_types=False)\n",
    "rb = em.RuleBasedBlocker()\n",
    "rb.add_rule(['Title_Title_lev_sim(ltuple, rtuple) < 0.4'], block_f)\n",
    "C = rb.block_candset(D, show_progress=False)\n",
    "print(\"C Set Size: \", len(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Saved off C set to a csv file in the data directory.\n",
    "\n",
    "We did a bit of debugging with ```em.debug_blocker(C, A, B, output_size=200)```\n",
    "\n",
    "We generated our set S with ```S = em.sample_table(C, 300)```\n",
    "\n",
    "We Then labeled our data with the ```G = em.label_table(S, 'label')```\n",
    "\n",
    "And finally saved G set to a csv file in the data directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML'ing a Matcher\n",
    "We executed ```createClassifier.py``` below is a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G Tuples: 300\n"
     ]
    }
   ],
   "source": [
    "path_G = '..' + os.sep + 'data' + os.sep + 'G.csv'\n",
    "G = em.read_csv_metadata(path_G, key='_id', ltable=A, rtable=B, fk_ltable='ltable_ID', fk_rtable='rtable_ID')\n",
    "print(\"G Tuples: \"+str(len(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Tuples: 210\n",
      "J Tuples: 90\n"
     ]
    }
   ],
   "source": [
    "# Create our Sets I & J\n",
    "IJ = em.split_train_test(G, train_proportion=0.7, random_state=0)\n",
    "I = IJ['train']\n",
    "J = IJ['test']\n",
    "print(\"I Tuples: \"+str(len(I)))\n",
    "print(\"J Tuples: \"+str(len(J)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table shows the corresponding attributes along with their respective types.\n",
      "Please confirm that the information  has been correctly inferred.\n",
      "If you would like to skip this validation process in the future,\n",
      "please set the flag validate_inferred_attr_types equal to false.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left Attribute</th>\n",
       "      <th>Right Attribute</th>\n",
       "      <th>Left Attribute Type</th>\n",
       "      <th>Right Attribute Type</th>\n",
       "      <th>Example Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>ID</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>Levenshtein Distance; Levenshtein Similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title</td>\n",
       "      <td>Title</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Score</td>\n",
       "      <td>Score</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Exact Match; Absolute Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rating</td>\n",
       "      <td>Rating</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genre</td>\n",
       "      <td>Genre</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>Levenshtein Distance; Levenshtein Similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Directed By</td>\n",
       "      <td>Directed By</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Written By</td>\n",
       "      <td>Written By</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Box Office</td>\n",
       "      <td>Box Office</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Exact Match; Absolute Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Release Date</td>\n",
       "      <td>Release Date</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>short string (1 word)</td>\n",
       "      <td>Levenshtein Distance; Levenshtein Similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Runtime</td>\n",
       "      <td>Runtime</td>\n",
       "      <td>numeric</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Exact Match; Absolute Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Studio</td>\n",
       "      <td>Studio</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>short string (1 word to 5 words)</td>\n",
       "      <td>Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Left Attribute Right Attribute               Left Attribute Type  \\\n",
       "0              ID              ID             short string (1 word)   \n",
       "1           Title           Title  short string (1 word to 5 words)   \n",
       "2           Score           Score                           numeric   \n",
       "3          Rating          Rating  short string (1 word to 5 words)   \n",
       "4           Genre           Genre             short string (1 word)   \n",
       "5     Directed By     Directed By  short string (1 word to 5 words)   \n",
       "6      Written By      Written By  short string (1 word to 5 words)   \n",
       "7      Box Office      Box Office                           numeric   \n",
       "8    Release Date    Release Date             short string (1 word)   \n",
       "9         Runtime         Runtime                           numeric   \n",
       "10         Studio          Studio  short string (1 word to 5 words)   \n",
       "\n",
       "                Right Attribute Type  \\\n",
       "0              short string (1 word)   \n",
       "1   short string (1 word to 5 words)   \n",
       "2                            numeric   \n",
       "3   short string (1 word to 5 words)   \n",
       "4              short string (1 word)   \n",
       "5   short string (1 word to 5 words)   \n",
       "6   short string (1 word to 5 words)   \n",
       "7                            numeric   \n",
       "8              short string (1 word)   \n",
       "9                            numeric   \n",
       "10  short string (1 word to 5 words)   \n",
       "\n",
       "                                                                               Example Features  \n",
       "0                                                  Levenshtein Distance; Levenshtein Similarity  \n",
       "1   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "2                                                                    Exact Match; Absolute Norm  \n",
       "3   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "4                                                  Levenshtein Distance; Levenshtein Similarity  \n",
       "5   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "6   Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  \n",
       "7                                                                    Exact Match; Absolute Norm  \n",
       "8                                                  Levenshtein Distance; Levenshtein Similarity  \n",
       "9                                                                    Exact Match; Absolute Norm  \n",
       "10  Jaccard Similarity [3-grams, 3-grams]; Cosine Similarity [Space Delimiter, Space Delimiter]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to proceed? (y/n):y\n"
     ]
    }
   ],
   "source": [
    "# Obtain our feature sets\n",
    "feature_table = em.get_features_for_matching(A, B, validate_inferred_attr_types=True)\n",
    "\n",
    "# extract our feature vectors from I\n",
    "H = em.extract_feature_vecs(I, feature_table=feature_table, attrs_after='label', show_progress=False)\n",
    "\n",
    "# Clean up some missing data.\n",
    "H.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Saved off I & J Sets to a csv file in the data directory\n",
    "\n",
    "We ran through the following classifers using(```em.select_matcher```) with precision and recall on set H (from I):\n",
    "1. ```em.DTMatcher(name='DecisionTree', random_state=0)```\n",
    "1. ```em.SVMMatcher(name='SVM', kernel='linear', random_state=0)```\n",
    "1. ```em.RFMatcher(name='RF', random_state=0)```\n",
    "1. ```em.LogRegMatcher(name='LogReg', random_state=0)```\n",
    "1. ```em.LinRegMatcher(name='LinReg')```\n",
    "1. ```em.NBMatcher(name='NaiveBayes')```\n",
    "\n",
    "We choose **Random Forest** as it has the highest F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our matcher\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0)\n",
    "svm = em.SVMMatcher(name='SVM', kernel='linear', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NaiveBayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Matcher  Average precision  Average recall  Average f1\n",
      "0  DecisionTree           0.966667        0.966667    0.966667\n",
      "1           SVM           0.971429        0.971429    0.969231\n",
      "2            RF           1.000000        0.966667    0.981818\n",
      "3        LogReg           0.950000        1.000000    0.971429\n",
      "4        LinReg           1.000000        0.869524    0.926263\n",
      "5    NaiveBayes           1.000000        0.926667    0.959596\n"
     ]
    }
   ],
   "source": [
    "# precision\n",
    "result = em.select_matcher([dt, svm, rf, lg, ln, nb], table=H,\n",
    "                           exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "                           k=5,\n",
    "                           target_attr='label', metric_to_select_matcher='precision', random_state=0)\n",
    "\n",
    "# recall\n",
    "result = em.select_matcher([dt, svm, rf, lg, ln, nb], table=H,\n",
    "                           exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "                           k=5,\n",
    "                           target_attr='label', metric_to_select_matcher='recall', random_state=0)\n",
    "print(result['cv_stats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Result-\n",
      "Precision : 100.0% (22/22)\n",
      "Recall : 100.0% (22/22)\n",
      "F1 : 100.0%\n",
      "False positives : 0 (out of 22 positive predictions)\n",
      "False negatives : 0 (out of 68 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Build up or test set feature vectors from J\n",
    "L = em.extract_feature_vecs(J, feature_table=feature_table, attrs_after='label', show_progress=False)\n",
    "\n",
    "# Clean up some missing data.\n",
    "L.fillna(value=0, inplace=True)\n",
    "\n",
    "#Fit to our set Development Set H (from I)\n",
    "rf.fit(table=H, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'], target_attr='label')\n",
    "\n",
    "# Use our test set L (from J) to measure the Matchers effectiveness\n",
    "predictions = rf.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "                         append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# How did it do?\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "print('\\nRandom Forest Result-')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating P/R/F1 for the other matchers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Result-\n",
      "Precision : 91.67% (22/24)\n",
      "Recall : 100.0% (22/22)\n",
      "F1 : 95.65%\n",
      "False positives : 2 (out of 24 positive predictions)\n",
      "False negatives : 0 (out of 66 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "dt.fit(table=H,\n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "       target_attr='label')\n",
    "\n",
    "predictions = dt.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "                         append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "print('\\nDecision Tree Result-')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Result-\n",
      "Precision : 87.5% (21/24)\n",
      "Recall : 95.45% (21/22)\n",
      "F1 : 91.3%\n",
      "False positives : 3 (out of 24 positive predictions)\n",
      "False negatives : 1 (out of 66 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "svm.fit(table=H,\n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "       target_attr='label')\n",
    "\n",
    "predictions = svm.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "                         append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "print('\\nSVM Result-')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
